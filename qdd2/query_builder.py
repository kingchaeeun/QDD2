"""
Search-query construction utilities.
"""

import logging
import re
from datetime import datetime
from typing import Dict, List, Optional, Tuple

from qdd2.name_resolution import resolve_person_name_en
from qdd2.translation import translate_ko_to_en

logger = logging.getLogger(__name__)


def _normalize_token(tok: str) -> str:
    """Normalize token for deduplication: lowercase, strip punctuation/extra spaces."""
    normalized = re.sub(r"[^\w\s]", " ", tok).lower()
    return " ".join(normalized.split()).strip()


def _dedupe_preserve(seq: List[str]) -> List[str]:
    """Remove duplicates while preserving order and ignoring empty tokens (punct/space-insensitive)."""
    seen = set()
    out: List[str] = []
    for item in seq:
        if not item:
            continue
        norm = _normalize_token(item)
        if not norm or norm in seen:
            continue
        seen.add(norm)
        out.append(item)
    return out

def _select_rollcall_focus_entity(
    entities: Optional[List[Dict[str, str]]],
    speaker_ko: Optional[str] = None,
) -> Tuple[str, str]:
    """
    Rollcall ëª¨ë“œì—ì„œ ì‚¬ìš©í•  'í¬ì»¤ìŠ¤ ì—”í‹°í‹°' 1ê°œ ì„ íƒ.

    - ìŠ¤í”¼ì»¤ì™€ ê²¹ì¹˜ëŠ” PSëŠ” ì œì™¸
    - ìš°ì„ ìˆœìœ„: LC > OG > PS
    - ê°™ì€ textëŠ” ë¹ˆë„/ê¸¸ì´ ê¸°ë°˜ìœ¼ë¡œ ìŠ¤ì½”ì–´ë§
    - ë°˜í™˜: (ko_text, en_text) (ì—†ìœ¼ë©´ ("",""))
    """
    if not entities:
        return "", ""

    # monologg/koelectra-base-v3-naver-ner ê¸°ì¤€
    LABEL_PRIORITY = {
        "LC": 3,  # ì¥ì†Œ
        "OG": 2,  # ì¡°ì§
        "PS": 1,  # ì‚¬ëŒ(ìŠ¤í”¼ì»¤ ì œì™¸)
    }

    stats: Dict[str, Dict[str, object]] = {}

    for ent in entities:
        text_val = (ent.get("text") or "").strip()
        if not text_val:
            continue

        raw_label = (
            ent.get("label")
            or ent.get("tag")
            or ent.get("ner")
            or ""
        )
        label = raw_label.replace("B-", "").replace("I-", "")

        # ê´€ì‹¬ ì—†ëŠ” ë ˆì´ë¸”ì€ ì œì™¸
        if label not in LABEL_PRIORITY:
            continue

        # ìŠ¤í”¼ì»¤ ì´ë¦„ê³¼ ê²¹ì¹˜ëŠ” PSëŠ” ì œì™¸
        if label == "PS" and speaker_ko:
            if text_val in speaker_ko or speaker_ko in text_val:
                continue

        key = text_val  # ê°™ì€ textëŠ” í•˜ë‚˜ë¡œ ë¬¶ìŒ
        entry = stats.get(key)
        if entry is None:
            stats[key] = {
                "label": label,
                "count": 1,
                "len": len(text_val),
                "translated": ent.get("translated", text_val),
            }
        else:
            entry["count"] = int(entry["count"]) + 1
            entry["len"] = max(int(entry["len"]), len(text_val))

    if not stats:
        return "", ""

    # ìŠ¤ì½”ì–´: ë ˆì´ë¸” ìš°ì„ ìˆœìœ„ -> ë“±ì¥ ë¹ˆë„ -> ê¸¸ì´
    def _score_item(item):
        text, info = item
        label = info["label"]
        count = info["count"]
        length = info["len"]
        base = LABEL_PRIORITY.get(label, 0)
        return (base, count, length)

    best_text, best_info = sorted(
        stats.items(),
        key=_score_item,
        reverse=True,
    )[0]

    return best_text, str(best_info.get("translated", best_text))


def generate_search_query(
    entities_by_type: Dict[str, List[str]],
    keywords: List[Tuple[str, float]],
    top_k: int = 3,
    quote_sentence: Optional[str] = None,
    article_date: Optional[str] = None,  # YYYY-MM-DD
    rollcall_mode: bool = False,
    use_wikidata: bool = True,
    # ğŸ”¥ ì¶”ê°€: NER ì—”í‹°í‹° ì›ë³¸ ë¦¬ìŠ¤íŠ¸ (text/label/translated ë“± ë“¤ì–´ìˆëŠ” dict ë¦¬ìŠ¤íŠ¸)
    entities: Optional[List[Dict[str, str]]] = None,
) -> Dict[str, Optional[str]]:
    """
    Build Korean/English search queries using entities + keywords.

    rollcall_mode=True:
        query_ko/en = [speaker] [article_date] [NER ê³ ìœ ëª…ì‚¬ 1ê°œ (PS/OG/LC)]
    default:
        query = speaker + location tokens + keyword tokens + optional quoted sentence
    """
    per_list = entities_by_type.get("PER", [])
    if not per_list:
        return {"ko": None, "en": None}

    speaker_ko = per_list[0]
    if use_wikidata:
        speaker_en = resolve_person_name_en(speaker_ko)
    else:
        try:
            speaker_en = translate_ko_to_en(speaker_ko)
        except Exception:
            speaker_en = speaker_ko

    # LOCëŠ” ì¼ë°˜ ëª¨ë“œì—ì„œë§Œ ì‚¬ìš©í•  ê±°ë¼ ê·¸ëŒ€ë¡œ ë‘ 
    loc_list = entities_by_type.get("LOC", [])[:2]
    loc_list = _dedupe_preserve(loc_list)
    locs_ko = " ".join(loc_list)
    locs_en_tokens: List[str] = []
    for loc in loc_list:
        try:
            loc_en_full = translate_ko_to_en(loc)
            loc_en_first = loc_en_full.split(",")[0]
            loc_en_first = " ".join(loc_en_first.split()[:2])
            if loc_en_first:
                locs_en_tokens.append(loc_en_first)
        except Exception:
            logger.warning("Location translation failed, falling back to original: %s", loc)
            locs_en_tokens.append(loc)

    top_kws_ko = [kw for kw, _ in keywords[:top_k]]
    top_kws_ko = _dedupe_preserve(top_kws_ko)
    kws_en_tokens: List[str] = []
    for kw_ko in top_kws_ko:
        try:
            kw_en_full = translate_ko_to_en(kw_ko)
            kw_en_trim = " ".join(kw_en_full.split()[:3])
            if kw_en_trim:
                kws_en_tokens.append(kw_en_trim)
        except Exception:
            logger.warning("Keyword translation failed, falling back to original: %s", kw_ko)
            kws_en_tokens.append(kw_ko)

    quote_en_full: Optional[str] = None
    if quote_sentence:
        try:
            quote_en_full = translate_ko_to_en(quote_sentence)
        except Exception:
            quote_en_full = None

    # =========================
    # 1) Rollcall ëª¨ë“œ ì „ìš© ë¸”ë¡
    # =========================
    if rollcall_mode and article_date:
        """
        [Rollcall ëª¨ë“œ - NER ì¤‘ì‹¬]
        êµ¬ì¡°: Speaker + Date + (í¬ì»¤ìŠ¤ ì—”í‹°í‹° 1ê°œ: NER ê¸°ë°˜)
        """
        # 1) ë‚ ì§œ ì˜ì–´ í¬ë§· ë³€í™˜
        try:
            dt = datetime.strptime(article_date, "%Y-%m-%d")
            date_en = dt.strftime("%B %d %Y")  # ì˜ˆ: November 26 2025
        except Exception:
            date_en = article_date

        target_word_ko = ""
        target_word_en = ""

        # 2-1) 1ìˆœìœ„: ì›ë³¸ NER ì—”í‹°í‹°ì—ì„œ í¬ì»¤ìŠ¤ ì—”í‹°í‹° ì„ íƒ
        focus_ko, focus_en = _select_rollcall_focus_entity(
            entities=entities,
            speaker_ko=speaker_ko,
        )
        if focus_ko:
            target_word_ko = focus_ko
            target_word_en = focus_en

        # 2-2) 2ìˆœìœ„: entities_by_type["LOC"] (loc_list) ì‚¬ìš©
        if (not target_word_ko) and loc_list:
            target_word_ko = loc_list[0]
            if locs_en_tokens:
                target_word_en = locs_en_tokens[0]
            else:
                target_word_en = target_word_ko

        # 2-3) 3ìˆœìœ„: ê·¸ë˜ë„ ì—†ìœ¼ë©´ KeyBERT keywordsì—ì„œ 1ê°œë§Œ fallback
        if (not target_word_ko) and keywords:
            # í™”ì ì´ë¦„ì´ ë“¤ì–´ê°„ í‚¤ì›Œë“œëŠ” ì „ë¶€ ì œì™¸í•˜ê³ ,
            # í‚¤ì›Œë“œ ë¬¸êµ¬ ì•ˆì—ì„œ 'ëª…ì‚¬ ê°™ì•„ ë³´ì´ëŠ” í† í°' í•˜ë‚˜ë§Œ ë½‘ì•„ì„œ ì‚¬ìš©
            for kw_text, _ in keywords:
                if not kw_text:
                    continue

                # í‚¤ì›Œë“œ ì „ì²´ì— í™”ì ì´ë¦„ì´ ë“¤ì–´ê°€ë©´ ìŠ¤í‚µ
                if speaker_ko and (speaker_ko in kw_text):
                    continue

                chosen_base = ""
                # í‚¤ì›Œë“œ ë¬¸êµ¬ë¥¼ í† í° ë‹¨ìœ„ë¡œ ìª¼ê°œì„œ ê²€ì‚¬
                for raw_tok in kw_text.split():
                    tok = raw_tok.strip()
                    if speaker_ko and (speaker_ko in tok):
                        # í† í°ì— í™”ì ì´ë¦„ ë“¤ì–´ê°€ë©´ ìŠ¤í‚µ
                        continue
                    if len(tok) < 2:
                        continue
                    # ìˆ«ì ì„ì¸ ê±´ ë²„ë¦¼
                    if re.search(r"\d", tok):
                        continue
                    # ì™„ì„±í˜• í•œê¸€ë§Œ ìš°ì„  ì‚¬ìš© (í•„ìš”ì— ë”°ë¼ ì™„í™” ê°€ëŠ¥)
                    if not re.fullmatch(r"[ê°€-í£]+", tok):
                        continue

                    # ì¡°ì‚¬/ì–´ë¯¸ë¥¼ ë–¼ì„œ ëª…ì‚¬ ê·¼ê°„ë§Œ ë‚¨ê¸°ê³  ê¸¸ì´ ì²´í¬
                    base = re.sub(
                        r"(ì—ì„œ|ì—ê²Œ|ë¶€í„°|ê¹Œì§€|ìœ¼ë¡œì¨|ìœ¼ë¡œì„œ|ìœ¼ë¡œ|ë§Œí¼|ë¿|ì¡°ì°¨|ë§ˆì €|ë§ˆë‹¤|ì²˜ëŸ¼|ê°™ì´|ë³´ë‹¤|ê»˜ì„œ|ë¼ê³ |í•˜ê³ |ì™€|ê³¼|ë‘|ì´ë‘|ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ì˜)$",
                        "",
                        tok,
                    )
                    if len(base) < 2:
                        continue

                    chosen_base = base
                    break  # ì´ í‚¤ì›Œë“œì—ì„œ ì“¸ í† í° í•˜ë‚˜ ì°¾ì•˜ìœ¼ë©´ íƒˆì¶œ

                if chosen_base:
                    target_word_ko = chosen_base
                    try:
                        kw_en_full = translate_ko_to_en(chosen_base)
                        target_word_en = " ".join(kw_en_full.split()[:3])
                    except Exception:
                        target_word_en = chosen_base
                    break  # fallback ì™„ì„±í–ˆìœ¼ë‹ˆ ì „ì²´ ë£¨í”„ íƒˆì¶œ

        # 3) EN ì¿¼ë¦¬ ì¡°ë¦½: [Speaker] [Date] [Entity?]
        parts_en: List[str] = []
        if speaker_en:
            parts_en.append(speaker_en)
        if date_en:
            parts_en.append(date_en)
        if target_word_en:
            parts_en.append(target_word_en)
        query_en = " ".join(parts_en).strip() or None

        # 4) KO ì¿¼ë¦¬ ì¡°ë¦½: [Speaker] [Date] [Entity?]
        parts_ko: List[str] = []
        if speaker_ko:
            parts_ko.append(speaker_ko)
        if article_date:
            parts_ko.append(article_date)
        if target_word_ko:
            parts_ko.append(target_word_ko)
        query_ko = " ".join(parts_ko).strip() or None

        return {"ko": query_ko, "en": query_en}



    # =========================
    # 2) ì¼ë°˜ ëª¨ë“œ (ê¸°ì¡´ ë¡œì§)
    # =========================
    query_en_tokens: List[str] = _dedupe_preserve(
        [speaker_en] + locs_en_tokens + kws_en_tokens
    )
    if quote_en_full:
        query_en_tokens.append(quote_en_full)
    query_en = " ".join(query_en_tokens).strip()

    query_ko_parts = [speaker_ko]
    if locs_ko:
        query_ko_parts.append(locs_ko)
    if top_kws_ko:
        query_ko_parts.append(" ".join(top_kws_ko))
    if quote_sentence:
        query_ko_parts.append(quote_sentence)
    query_ko = " ".join(
        _dedupe_preserve(" ".join(query_ko_parts).split())
    ).strip()

    return {"ko": query_ko or None, "en": query_en or None}
